{"cells":[{"cell_type":"markdown","id":"2acae095-3914-4454-bd69-12c8705d9548","metadata":{"id":"2acae095-3914-4454-bd69-12c8705d9548"},"source":["#### Load the Dataset into Spark\n"]},{"cell_type":"code","execution_count":1,"id":"78809fa4-a7c8-490b-9e39-e76b097bb9bb","metadata":{"id":"78809fa4-a7c8-490b-9e39-e76b097bb9bb","executionInfo":{"status":"error","timestamp":1752675694401,"user_tz":-60,"elapsed":21503,"user":{"displayName":"Roukaya Lakhzouri","userId":"08983813094602701347"}},"outputId":"8f2bcbff-01d5-4a40-b89a-257c9c9bedab","colab":{"base_uri":"https://localhost:8080/","height":321}},"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"[PATH_NOT_FOUND] Path does not exist: file:/content/train.csv.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-43635216.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TreeCoverClassification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/train.csv."]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"TreeCoverClassification\").getOrCreate()\n","df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n"]},{"cell_type":"markdown","id":"0940ac6c-c45e-4b68-8613-1cc90d627b89","metadata":{"id":"0940ac6c-c45e-4b68-8613-1cc90d627b89"},"source":["#### Separate Features and Target\n","\n"]},{"cell_type":"code","execution_count":null,"id":"5848f53e-5cca-4a20-a0d4-21eaa8bed93d","metadata":{"id":"5848f53e-5cca-4a20-a0d4-21eaa8bed93d"},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","\n","feature_cols = [col for col in df.columns if col != \"Cover_Type\"]\n","assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","df = assembler.transform(df)\n","\n","# Rename target column for clarity\n","df = df.withColumnRenamed(\"Cover_Type\", \"label\")\n"]},{"cell_type":"markdown","id":"9202ebe5-2971-43ec-ab7f-794f30df8027","metadata":{"id":"9202ebe5-2971-43ec-ab7f-794f30df8027"},"source":["#### Split the data into training and testing sets.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6bf7537c-1b4f-43ba-9709-b9bd5e051b3c","metadata":{"id":"6bf7537c-1b4f-43ba-9709-b9bd5e051b3c"},"outputs":[],"source":["train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n"]},{"cell_type":"markdown","id":"f9ebb234-600d-4e63-b0ec-7ff3a005d547","metadata":{"id":"f9ebb234-600d-4e63-b0ec-7ff3a005d547"},"source":["#### Standardize the Features\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"961eeb66-4963-437f-a67b-f3e98b3312a1","metadata":{"id":"961eeb66-4963-437f-a67b-f3e98b3312a1"},"outputs":[],"source":["from pyspark.ml.feature import StandardScaler\n","\n","scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n","scaler_model = scaler.fit(train_data)\n","train_data = scaler_model.transform(train_data)\n","test_data = scaler_model.transform(test_data)\n"]},{"cell_type":"markdown","id":"1a889138-a3e1-454a-9a00-3057bb7b7d6c","metadata":{"id":"1a889138-a3e1-454a-9a00-3057bb7b7d6c"},"source":["#### Replace DecisionTreeClassifier and RandomForestClassifier from scikit-learn with Spark MLlib versions\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"7d057b77-f9d6-4be3-9570-74dcf9722ef4","metadata":{"id":"7d057b77-f9d6-4be3-9570-74dcf9722ef4"},"outputs":[],"source":["from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier ,GBTClassifier\n","\n","# Decision Tree\n","dt = DecisionTreeClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\")\n","dt_model = dt.fit(train_data)\n","dt_predictions = dt_model.transform(test_data)\n","\n","# Random Forest\n","rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\", numTrees=100)\n","rf_model = rf.fit(train_data)\n","rf_predictions = rf_model.transform(test_data)\n","\n"]},{"cell_type":"markdown","id":"9cc78fba-68bf-4de9-882c-f12f2218216a","metadata":{"id":"9cc78fba-68bf-4de9-882c-f12f2218216a"},"source":["#### Results\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"0aa9dcaf-d3fd-45c2-a2f0-f10bf423c510","metadata":{"id":"0aa9dcaf-d3fd-45c2-a2f0-f10bf423c510","outputId":"733fe1fb-08e7-4286-a175-cbda4dd94e7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6668914362778152\n","F1 Score: 0.6485856839016301\n"]}],"source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n","\n","# Accuracy\n","accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy = accuracy_evaluator.evaluate(dt_predictions)\n","\n","# F1 Score\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n","f1_score = f1_evaluator.evaluate(dt_predictions)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score: {f1_score}\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"801e2a07-7256-4164-9646-d1d593cac941","metadata":{"id":"801e2a07-7256-4164-9646-d1d593cac941","outputId":"0a6a560c-b1fe-4ef7-ff8d-d55fa9ce1ecf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7039784221173297\n","F1 Score: 0.6900678760250907\n"]}],"source":["# Accuracy\n","accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy1 = accuracy_evaluator.evaluate(rf_predictions)\n","\n","# F1 Score\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n","f1_score1 = f1_evaluator.evaluate(rf_predictions)\n","\n","print(f\"Accuracy: {accuracy1}\")\n","print(f\"F1 Score: {f1_score1}\")\n","\n","\n"]},{"cell_type":"markdown","id":"6e810193-8a44-420f-a723-3a09f29ab0c6","metadata":{"id":"6e810193-8a44-420f-a723-3a09f29ab0c6"},"source":["#### Trying to improve Random Forest"]},{"cell_type":"code","execution_count":null,"id":"6709a1dc-535f-44d5-bce0-271cc2a63438","metadata":{"id":"6709a1dc-535f-44d5-bce0-271cc2a63438"},"outputs":[],"source":["# Random Forest\n","rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\", numTrees=100,minInstancesPerNode=5,maxDepth= 7)\n","rf_model = rf.fit(train_data)\n","rf_predictions = rf_model.transform(test_data)\n"]},{"cell_type":"code","execution_count":null,"id":"16bc107e-8bfb-4688-941d-66b97e8cebb3","metadata":{"id":"16bc107e-8bfb-4688-941d-66b97e8cebb3","outputId":"1ad2227e-d52e-46ce-a962-8e38041a614c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.7400539447066756\n","F1 Score: 0.7309724431620451\n"]}],"source":["# Accuracy\n","accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n","accuracy2 = accuracy_evaluator.evaluate(rf_predictions)\n","\n","# F1 Score\n","f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n","f1_score2 = f1_evaluator.evaluate(rf_predictions)\n","\n","print(f\"Accuracy: {accuracy2}\")\n","print(f\"F1 Score: {f1_score2}\")\n"]},{"cell_type":"code","execution_count":null,"id":"2449af09-df81-42fe-a696-306109f177d2","metadata":{"id":"2449af09-df81-42fe-a696-306109f177d2","outputId":"6d927ae9-ef46-4258-d0dd-93c5db5a7065"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Accuracy: 0.7400539447066756\n","Random Forest F1 Score: 0.7309666287772693\n"]}],"source":["# Random Forest\n","rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\", numTrees=100,minInstancesPerNode=5,maxDepth= 7,subsamplingRate = 0.5)\n","rf_model = rf.fit(train_data)\n","rf_predictions = rf_model.transform(test_data)\n","\n","\n","# Train the model\n","rf_model = rf.fit(train_data)\n","\n","# Make predictions\n","rf_predictions = rf_model.transform(test_data)\n","\n","# Evaluate the model (accuracy, F1 score, etc.)\n","accuracy = accuracy_evaluator.evaluate(rf_predictions)\n","f1_score = f1_evaluator.evaluate(rf_predictions)\n","\n","print(f\"Random Forest Accuracy: {accuracy}\")\n","print(f\"Random Forest F1 Score: {f1_score}\")\n"]},{"cell_type":"code","execution_count":null,"id":"6a8f4f26-c07e-47df-8ab3-719191986c9a","metadata":{"id":"6a8f4f26-c07e-47df-8ab3-719191986c9a","outputId":"9fa9a1c7-0bcd-411f-f518-348081967421"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Accuracy: 0.7400539447066756\n","Random Forest F1 Score: 0.7309666287772693\n"]}],"source":["# Random Forest\n","rf = RandomForestClassifier(featuresCol=\"scaledFeatures\", labelCol=\"label\", numTrees=100,minInstancesPerNode=5,maxDepth= 7,subsamplingRate = 0.5)\n","rf_model = rf.fit(train_data)\n","rf_predictions = rf_model.transform(test_data)\n","\n","\n","# Train the model\n","rf_model = rf.fit(train_data)\n","\n","# Make predictions\n","rf_predictions = rf_model.transform(test_data)\n","\n","# Evaluate the model (accuracy, F1 score, etc.)\n","accuracy = accuracy_evaluator.evaluate(rf_predictions)\n","f1_score = f1_evaluator.evaluate(rf_predictions)\n","\n","print(f\"Random Forest Accuracy: {accuracy}\")\n","print(f\"Random Forest F1 Score: {f1_score}\")\n"]},{"cell_type":"markdown","id":"b576a4b5-5d63-49e7-8ef8-8097483f7eb2","metadata":{"id":"b576a4b5-5d63-49e7-8ef8-8097483f7eb2"},"source":["After adjusting the model's parameters, I found that the optimal configuration was achieved with the following settings: numTrees=100, minInstancesPerNode=5, maxDepth=7, and subsamplingRate=0.5.\n","\n","With these parameters, the Random Forest model achieved an accuracy of 72.66% and an F1 score of 71.64%\n","\n","\n","### Save the Trained Model\n"]},{"cell_type":"code","execution_count":null,"id":"8d8c552e-1c58-43bc-8e0a-4531444ac14d","metadata":{"id":"8d8c552e-1c58-43bc-8e0a-4531444ac14d"},"outputs":[],"source":["import os\n","os.environ['HADOOP_HOME'] = 'C:\\\\hadoop'\n","os.environ['PATH'] += os.pathsep + os.path.join(os.environ['HADOOP_HOME'], 'bin')"]},{"cell_type":"code","execution_count":null,"id":"c3b7391e-ef31-4e42-86a6-bca2aa7ebd17","metadata":{"id":"c3b7391e-ef31-4e42-86a6-bca2aa7ebd17","outputId":"5bc42486-e69f-4707-bcb1-a84c679f1dd2"},"outputs":[{"ename":"AttributeError","evalue":"'RandomForestClassificationModel' object has no attribute 'predict_from_list'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 148\u001b[0m\n\u001b[0;32m    145\u001b[0m     predictor\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 148\u001b[0m     main()\n","Cell \u001b[1;32mIn[13], line 141\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Id\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;241m2500.0\u001b[39m,  \u001b[38;5;66;03m# Elevation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;241m*\u001b[39m([\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)  \u001b[38;5;66;03m# Soil Types (40 zeros as placeholder)\u001b[39;00m\n\u001b[0;32m    138\u001b[0m ]\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Make a prediction\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m prediction \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict_from_list(sample_input)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Forest Cover Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Close the Spark session\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassificationModel' object has no attribute 'predict_from_list'"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.ml import PipelineModel\n","from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql.types import StructType, StructField, DoubleType, IntegerType\n","\n","class ForestCoverPredictor:\n","    def __init__(self, model_path):\n","        # Initialize Spark Session\n","        self.spark = SparkSession.builder \\\n","            .appName(\"ForestCoverTypePrediction\") \\\n","            .getOrCreate()\n","\n","        # Load the saved model\n","        self.model = RandomForestClassificationModel.load(model_path)\n","\n","        # Define feature columns\n","        self.feature_columns = [\n","            'Elevation', 'Aspect', 'Slope',\n","            'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n","            'Horizontal_Distance_To_Roadways',\n","            'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n","            'Horizontal_Distance_To_Fire_Points'\n","        ]\n","\n","        # Add Wilderness Area columns\n","        self.feature_columns.extend([\n","            'Wilderness_Area1', 'Wilderness_Area2',\n","            'Wilderness_Area3', 'Wilderness_Area4'\n","        ])\n","\n","        # Add Soil Type columns\n","        self.feature_columns.extend([f'Soil_Type{i}' for i in range(1, 41)])\n","\n","        # Create feature assembler\n","        self.assembler = VectorAssembler(\n","            inputCols=self.feature_columns,\n","            outputCol=\"features\"\n","        )\n","\n","        # Create scaler\n","        self.scaler = StandardScaler(\n","            inputCol=\"features\",\n","            outputCol=\"scaledFeatures\",\n","            withStd=True,\n","            withMean=True\n","        )\n","\n","    def create_prediction_schema(self):\n","        \"\"\"\n","        Create a schema for input data\n","        \"\"\"\n","        schema = StructType([\n","            StructField(\"Id\", IntegerType(), True)\n","        ] + [\n","            StructField(col, DoubleType(), True)\n","            for col in self.feature_columns\n","        ])\n","        return schema\n","\n","    def preprocess_data(self, input_data):\n","        \"\"\"\n","        Preprocess input data for prediction\n","        \"\"\"\n","        # Assemble features\n","        assembled = self.assembler.transform(input_data)\n","\n","        # Scale features\n","        scaled = self.scaler.transform(assembled)\n","\n","        return scaled\n","\n","    def predict(self, input_data):\n","        \"\"\"\n","        Make predictions on input data\n","\n","        Args:\n","        input_data (spark.DataFrame): DataFrame with feature columns\n","\n","        Returns:\n","        spark.DataFrame: DataFrame with predictions\n","        \"\"\"\n","        # Preprocess data\n","        preprocessed = self.preprocess_data(input_data)\n","\n","        # Make predictions\n","        predictions = self.model.transform(preprocessed)\n","\n","        return predictions\n","\n","    def predict_from_list(self, input_list):\n","        \"\"\"\n","        Make prediction from a list of feature values\n","\n","        Args:\n","        input_list (list): List of feature values matching the feature columns\n","\n","        Returns:\n","        int: Predicted forest cover type\n","        \"\"\"\n","        # Create DataFrame from input list\n","        df = self.spark.createDataFrame([input_list], schema=self.create_prediction_schema())\n","\n","        # Make prediction\n","        predictions = self.predict(df)\n","\n","        # Return predicted cover type\n","        return predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","\n","    def close(self):\n","        \"\"\"\n","        Close the Spark session\n","        \"\"\"\n","        self.spark.stop()\n","\n","# Example Usage\n","def main():\n","    # Path where the model was saved\n","\n","    # Initialize the predictor\n","    predictor = rf_model\n","\n","    # Example input (replace with actual values)\n","    sample_input = [\n","        1,  # Id\n","        2500.0,  # Elevation\n","        180.0,  # Aspect\n","        15.0,  # Slope\n","        300.0,  # Horizontal_Distance_To_Hydrology\n","        50.0,   # Vertical_Distance_To_Hydrology\n","        1500.0, # Horizontal_Distance_To_Roadways\n","        200.0,  # Hillshade_9am\n","        250.0,  # Hillshade_Noon\n","        180.0,  # Hillshade_3pm\n","        2000.0, # Horizontal_Distance_To_Fire_Points\n","        1, 0, 0, 0,  # Wilderness Areas\n","        *([0] * 40)  # Soil Types (40 zeros as placeholder)\n","    ]\n","\n","    # Make a prediction\n","    prediction = predictor.predict_from_list(sample_input)\n","    print(f\"Predicted Forest Cover Type: {prediction}\")\n","\n","    # Close the Spark session\n","    predictor.close()\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"id":"7f7e1047-9837-4e95-a551-8e0ed062fec2","metadata":{"id":"7f7e1047-9837-4e95-a551-8e0ed062fec2"},"outputs":[],"source":["#!pip install gradio\n","#!pip install --upgrade typing_extensions\n","#!pip show typing_extensions\n","#!pip install --upgrade gradio pydantic fastapi\n","!pip install --upgrade typing-extensions\n"]},{"cell_type":"code","execution_count":null,"id":"753b0db3-725a-4f09-b491-9ff26209dbb4","metadata":{"id":"753b0db3-725a-4f09-b491-9ff26209dbb4"},"outputs":[],"source":["import gradio as gr\n"]},{"cell_type":"code","execution_count":null,"id":"6c9d3633-ea6f-40c8-9212-1ec7eecf5119","metadata":{"id":"6c9d3633-ea6f-40c8-9212-1ec7eecf5119","outputId":"78936f81-f05d-4cb5-af23-f61f366a351c"},"outputs":[{"ename":"AttributeError","evalue":"module 'gradio' has no attribute 'inputs'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(prediction)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Define Gradio interface\u001b[39;00m\n\u001b[0;32m     41\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 42\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     43\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mElevation\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     44\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAspect\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     45\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSlope\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     46\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorizontal Distance to Hydrology\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     47\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVertical Distance to Hydrology\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     48\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorizontal Distance to Roadways\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     49\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHillshade 9am\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     50\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHillshade Noon\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     51\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHillshade 3pm\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     52\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mNumber(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHorizontal Distance to Fire Points\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     53\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilderness Area 1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     54\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilderness Area 2\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     55\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilderness Area 3\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     56\u001b[0m     gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilderness Area 4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m ] \u001b[38;5;241m+\u001b[39m [gr\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mCheckbox(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoil Type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m41\u001b[39m)]\n\u001b[0;32m     59\u001b[0m output \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mLabel(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCover Type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m app \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mInterface(fn\u001b[38;5;241m=\u001b[39mpredict_forest_cover, inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutput, live\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[1;31mAttributeError\u001b[0m: module 'gradio' has no attribute 'inputs'"]}],"source":["\n","from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql import SparkSession\n","import gradio as gr\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestDeployment\") \\\n","    .getOrCreate()\n","\n","# Load the trained Random Forest model\n","model = rf_model\n","\n","# Define the prediction function\n","def predict_forest_cover(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","                         Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","                         Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","                         Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","                         Wilderness_Area3, Wilderness_Area4, *Soil_Types):\n","    # Create a DataFrame for the input\n","    data = [(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","             Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","             Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","             Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","             Wilderness_Area3, Wilderness_Area4, *Soil_Types)]\n","    columns = [\n","        \"Id\", \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n","        \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n","        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n","        \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\",\n","        \"Wilderness_Area3\", \"Wilderness_Area4\"\n","    ] + [f\"Soil_Type{i}\" for i in range(1, 41)]\n","\n","    input_df = spark.createDataFrame(data, columns)\n","\n","    # Make predictions\n","    predictions = model.transform(input_df)\n","    prediction = predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","    return int(prediction)\n","\n","# Define Gradio interface\n","inputs = [\n","    gr.inputs.Number(label=\"Id\"),\n","    gr.inputs.Number(label=\"Elevation\"),\n","    gr.inputs.Number(label=\"Aspect\"),\n","    gr.inputs.Number(label=\"Slope\"),\n","    gr.inputs.Number(label=\"Horizontal Distance to Hydrology\"),\n","    gr.inputs.Number(label=\"Vertical Distance to Hydrology\"),\n","    gr.inputs.Number(label=\"Horizontal Distance to Roadways\"),\n","    gr.inputs.Number(label=\"Hillshade 9am\"),\n","    gr.inputs.Number(label=\"Hillshade Noon\"),\n","    gr.inputs.Number(label=\"Hillshade 3pm\"),\n","    gr.inputs.Number(label=\"Horizontal Distance to Fire Points\"),\n","    gr.inputs.Checkbox(label=\"Wilderness Area 1\"),\n","    gr.inputs.Checkbox(label=\"Wilderness Area 2\"),\n","    gr.inputs.Checkbox(label=\"Wilderness Area 3\"),\n","    gr.inputs.Checkbox(label=\"Wilderness Area 4\")\n","] + [gr.inputs.Checkbox(label=f\"Soil Type {i}\") for i in range(1, 41)]\n","\n","output = gr.outputs.Label(label=\"Cover Type\")\n","\n","app = gr.Interface(fn=predict_forest_cover, inputs=inputs, outputs=output, live=True)\n","\n","# Launch the app\n","app.launch()\n"]},{"cell_type":"code","execution_count":null,"id":"5f192d36-d717-4da0-8865-285de3b6c38f","metadata":{"id":"5f192d36-d717-4da0-8865-285de3b6c38f"},"outputs":[],"source":["from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql import SparkSession\n","import gradio as gr\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestDeployment\") \\\n","    .getOrCreate()\n","\n","# Load the trained Random Forest model\n","model_path = \"path_to_your_saved_model\"\n","model = rf_model\n","\n","\n","# Define the prediction function\n","def predict_forest_cover(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","                         Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","                         Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","                         Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","                         Wilderness_Area3, Wilderness_Area4, *Soil_Types):\n","    # Convert Checkbox inputs to integers (1 if checked, else 0)\n","    wilderness_areas = [int(Wilderness_Area1), int(Wilderness_Area2), int(Wilderness_Area3), int(Wilderness_Area4)]\n","    soil_types = [int(soil) for soil in Soil_Types]\n","\n","    # Create a DataFrame for the input\n","    data = [(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","             Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","             Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","             Horizontal_Distance_To_Fire_Points, *wilderness_areas, *soil_types)]\n","    columns = [\n","        \"Id\", \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n","        \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n","        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n","        \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\",\n","        \"Wilderness_Area3\", \"Wilderness_Area4\"\n","    ] + [f\"Soil_Type{i}\" for i in range(1, 41)]\n","\n","    input_df = spark.createDataFrame(data, columns)\n","\n","    # Make predictions\n","    predictions = model.transform(input_df)\n","    prediction = predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","    return int(prediction)\n","\n","# Define Gradio interface\n","inputs = [\n","    gr.Number(label=\"Id\"),\n","    gr.Number(label=\"Elevation\"),\n","    gr.Number(label=\"Aspect\"),\n","    gr.Number(label=\"Slope\"),\n","    gr.Number(label=\"Horizontal Distance to Hydrology\"),\n","    gr.Number(label=\"Vertical Distance to Hydrology\"),\n","    gr.Number(label=\"Horizontal Distance to Roadways\"),\n","    gr.Number(label=\"Hillshade 9am\"),\n","    gr.Number(label=\"Hillshade Noon\"),\n","    gr.Number(label=\"Hillshade 3pm\"),\n","    gr.Number(label=\"Horizontal Distance to Fire Points\"),\n","    gr.Checkbox(label=\"Wilderness Area 1\"),\n","    gr.Checkbox(label=\"Wilderness Area 2\"),\n","    gr.Checkbox(label=\"Wilderness Area 3\"),\n","    gr.Checkbox(label=\"Wilderness Area 4\")\n","] + [gr.Checkbox(label=f\"Soil Type {i}\") for i in range(1, 41)]\n","\n","output = gr.Label(label=\"Cover Type\")\n","\n","app = gr.Interface(fn=predict_forest_cover, inputs=inputs, outputs=output, live=True)\n","\n","# Launch the app\n","app.launch()\n"]},{"cell_type":"code","execution_count":null,"id":"de80aa4c-321f-401f-a95d-700a51373a64","metadata":{"id":"de80aa4c-321f-401f-a95d-700a51373a64"},"outputs":[],"source":["from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql import SparkSession\n","import gradio as gr\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestDeployment\") \\\n","    .getOrCreate()\n","\n","# Load the trained Random Forest model\n","model_path = \"path_to_your_saved_model\"\n","model = RandomForestClassificationModel.load(model_path)\n","\n","# Define the prediction function\n","def predict_cover_type(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","                       Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","                       Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","                       Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","                       Wilderness_Area3, Wilderness_Area4, Soil_Types):\n","    # Prepare input data as a dictionary\n","    input_data = {\n","        \"Id\": Id,\n","        \"Elevation\": Elevation,\n","        \"Aspect\": Aspect,\n","        \"Slope\": Slope,\n","        \"Horizontal_Distance_To_Hydrology\": Horizontal_Distance_To_Hydrology,\n","        \"Vertical_Distance_To_Hydrology\": Vertical_Distance_To_Hydrology,\n","        \"Horizontal_Distance_To_Roadways\": Horizontal_Distance_To_Roadways,\n","        \"Hillshade_9am\": Hillshade_9am,\n","        \"Hillshade_Noon\": Hillshade_Noon,\n","        \"Hillshade_3pm\": Hillshade_3pm,\n","        \"Horizontal_Distance_To_Fire_Points\": Horizontal_Distance_To_Fire_Points,\n","        \"Wilderness_Area1\": int(Wilderness_Area1),\n","        \"Wilderness_Area2\": int(Wilderness_Area2),\n","        \"Wilderness_Area3\": int(Wilderness_Area3),\n","        \"Wilderness_Area4\": int(Wilderness_Area4),\n","    }\n","\n","    # Add Soil Type columns dynamically\n","    for i in range(1, 41):\n","        input_data[f\"Soil_Type{i}\"] = 1 if i in Soil_Types else 0\n","\n","    # Convert to Spark DataFrame\n","    input_df = spark.createDataFrame([input_data])\n","\n","    # Perform prediction\n","    predictions = model.transform(input_df)\n","    prediction = predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","\n","    return f\"Predicted Cover Type: {int(prediction)}\"\n","\n","# Define Gradio interface\n","inputs = [\n","    gr.Number(label=\"Id\"),\n","    gr.Number(label=\"Elevation\"),\n","    gr.Number(label=\"Aspect\"),\n","    gr.Number(label=\"Slope\"),\n","    gr.Number(label=\"Horizontal Distance to Hydrology\"),\n","    gr.Number(label=\"Vertical Distance to Hydrology\"),\n","    gr.Number(label=\"Horizontal Distance to Roadways\"),\n","    gr.Number(label=\"Hillshade 9am\"),\n","    gr.Number(label=\"Hillshade Noon\"),\n","    gr.Number(label=\"Hillshade 3pm\"),\n","    gr.Number(label=\"Horizontal Distance to Fire Points\"),\n","    gr.Checkbox(label=\"Wilderness Area 1\"),\n","    gr.Checkbox(label=\"Wilderness Area 2\"),\n","    gr.Checkbox(label=\"Wilderness Area 3\"),\n","    gr.Checkbox(label=\"Wilderness Area 4\"),\n","    gr.CheckboxGroup([i for i in range(1, 41)], label=\"Select Soil Types\"),\n","]\n","\n","output = gr.Textbox(label=\"Prediction Result\")\n","\n","# Create Gradio interface\n","app = gr.Interface(fn=predict_cover_type, inputs=inputs, outputs=output)\n","\n","# Launch the app\n","app.launch()\n"]},{"cell_type":"code","execution_count":null,"id":"ac9f8fee-8c4a-47a3-b2b6-7549120aaf7f","metadata":{"id":"ac9f8fee-8c4a-47a3-b2b6-7549120aaf7f"},"outputs":[],"source":["import pkg_resources\n","\n","requirements = [\n","    \"aiofiles>=22.0,<24.0\",\n","    \"anyio>=3.0,<5.0\",\n","    \"fastapi>=0.115.2,<1.0\",\n","    \"ffmpy\",\n","    \"gradio_client==1.5.2\",\n","    \"httpx>=0.24.1\",\n","    \"huggingface_hub>=0.25.1\",\n","    \"Jinja2<4.0\",\n","    \"markupsafe~=2.0\",\n","    \"numpy>=1.0,<3.0\",\n","    \"orjson~=3.0\",\n","    \"packaging\",\n","    \"pandas>=1.0,<3.0\",\n","    \"pillow>=8.0,<12.0\",\n","    \"pydantic>=2.0\",\n","    \"python-multipart>=0.0.18\",\n","    \"pydub\",\n","    \"pyyaml>=5.0,<7.0\",\n","    \"ruff>=0.2.2\",\n","    \"safehttpx>=0.1.6,<0.2.0\",\n","    \"semantic_version~=2.0\",\n","    \"starlette>=0.40.0,<1.0\",\n","    \"tomlkit>=0.12.0,<0.14.0\",\n","    \"typer>=0.12,<1.0\",\n","    \"typing_extensions~=4.0\",\n","    \"uvicorn>=0.14.0\",\n","]\n","\n","for req in requirements:\n","    try:\n","        pkg_resources.require(req)\n","        print(f\"{req} is satisfied.\")\n","    except pkg_resources.DistributionNotFound as e:\n","        print(f\"{req} is NOT installed: {e}\")\n","    except pkg_resources.VersionConflict as e:\n","        print(f\"{req} has a version conflict: {e}\")\n"]},{"cell_type":"code","execution_count":null,"id":"cd5854a7-3474-4b55-902a-1991051e4a4a","metadata":{"id":"cd5854a7-3474-4b55-902a-1991051e4a4a"},"outputs":[],"source":["#!pip uninstall typing_extensions\n","#!pip install typing_extensions~=4.0\n"]},{"cell_type":"code","execution_count":null,"id":"43d4c160-2fb1-4ed0-b7e6-36085512e38f","metadata":{"id":"43d4c160-2fb1-4ed0-b7e6-36085512e38f"},"outputs":[],"source":["#!pip show typing_extensions\n"]},{"cell_type":"code","execution_count":null,"id":"f05d1dde-675f-40ac-b33d-a8f83e2ec6ad","metadata":{"id":"f05d1dde-675f-40ac-b33d-a8f83e2ec6ad"},"outputs":[],"source":["#!pip uninstall typing_extensions\n"]},{"cell_type":"code","execution_count":null,"id":"a4bc0731-da7f-4f16-9ed2-1bc74be8c5d2","metadata":{"id":"a4bc0731-da7f-4f16-9ed2-1bc74be8c5d2"},"outputs":[],"source":["#!pip install typing_extensions==4.0\n"]},{"cell_type":"code","execution_count":null,"id":"b7a84f4d-f71b-4798-8af3-8eb274122fd7","metadata":{"id":"b7a84f4d-f71b-4798-8af3-8eb274122fd7"},"outputs":[],"source":["#!pip install --upgrade typing-extensions\n"]},{"cell_type":"code","execution_count":null,"id":"70bd3736-0496-44b6-92f0-81afb24fb8ef","metadata":{"id":"70bd3736-0496-44b6-92f0-81afb24fb8ef"},"outputs":[],"source":["#!pip install huggingface_hub\n"]},{"cell_type":"code","execution_count":null,"id":"bef0ecfc-ff55-488e-ba6e-f4331b77d86e","metadata":{"id":"bef0ecfc-ff55-488e-ba6e-f4331b77d86e","outputId":"2fea30b0-338e-4129-8f9b-de5e5811e118"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.11.7\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"id":"057269be-2c15-4ae6-9bcb-ee35c8e2491e","metadata":{"id":"057269be-2c15-4ae6-9bcb-ee35c8e2491e","outputId":"6e0dc532-c089-4056-a341-7d12cfbe86c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: gradio\n","Version: 5.9.0\n","Summary: Python library for easily interacting with trained machine learning models\n","Home-page: https://github.com/gradio-app/gradio\n","Author: \n","Author-email: Abubakar Abid <gradio-team@huggingface.co>, Ali Abid <gradio-team@huggingface.co>, Ali Abdalla <gradio-team@huggingface.co>, Dawood Khan <gradio-team@huggingface.co>, Ahsen Khaliq <gradio-team@huggingface.co>, Pete Allen <gradio-team@huggingface.co>, Ömer Faruk Özdemir <gradio-team@huggingface.co>, Freddy A Boulton <gradio-team@huggingface.co>, Hannah Blair <gradio-team@huggingface.co>\n","License: Apache-2.0\n","Location: C:\\Users\\user\\anaconda3\\Lib\\site-packages\n","Requires: aiofiles, anyio, fastapi, ffmpy, gradio-client, httpx, huggingface-hub, jinja2, markupsafe, numpy, orjson, packaging, pandas, pillow, pydantic, pydub, python-multipart, pyyaml, ruff, safehttpx, semantic-version, starlette, tomlkit, typer, typing-extensions, uvicorn\n","Required-by: \n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n"]},{"name":"stdout","output_type":"stream","text":["Using existing dataset file at: .gradio\\flagged\\dataset1.csv\n"]}],"source":["!pip show gradio"]},{"cell_type":"code","execution_count":null,"id":"ecb0f4e3-79d2-4567-b3c6-8da636508c93","metadata":{"id":"ecb0f4e3-79d2-4567-b3c6-8da636508c93"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"470718b0-17d2-4fc4-aa09-1fdc8a3a9e05","metadata":{"id":"470718b0-17d2-4fc4-aa09-1fdc8a3a9e05","outputId":"4311db03-addf-4894-8771-fde03f0bdf90"},"outputs":[{"name":"stdout","output_type":"stream","text":["* Running on local URL:  http://127.0.0.1:7861\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":17,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n","Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\3858942945.py\", line 45, in predict_forest_cover\n","    scaled_df = scaler.transform(input_df)\n","                ^^^^^^^^^^^^^^^^\n","AttributeError: 'StandardScaler' object has no attribute 'transform'\n"]}],"source":["import gradio as gr\n","from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import StandardScaler\n","from pyspark.ml import Pipeline\n","from pyspark.sql import functions as F\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestDeployment\") \\\n","    .getOrCreate()\n","\n","# Load the trained Random Forest model\n","model_path = \"path_to_your_saved_model\"\n","model = rf_model\n","\n","# Define the prediction function\n","def predict_forest_cover(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","                         Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","                         Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","                         Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","                         Wilderness_Area3, Wilderness_Area4, *Soil_Types):\n","    # Create a DataFrame for the input\n","    data = [(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","             Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","             Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","             Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","             Wilderness_Area3, Wilderness_Area4, *Soil_Types)]\n","    columns = [\n","        \"Id\", \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n","        \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n","        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n","        \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\",\n","        \"Wilderness_Area3\", \"Wilderness_Area4\"\n","    ] + [f\"Soil_Type{i}\" for i in range(1, 41)]\n","\n","\n","\n","    # Assuming the features in input_df are already in vector format, we can scale them\n","\n","    # Define the StandardScaler\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n","\n","    # Apply the scaler to the input dataframe\n","    scaled_df = scaler.transform(input_df)\n","\n","    # Now pass the scaled features to the model for prediction\n","    predictions = model.transform(scaled_df)\n","    prediction = predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","\n","    return int(prediction)\n","\n","# Define Gradio interface\n","inputs = [\n","    gr.Number(label=\"Id\"),\n","    gr.Number(label=\"Elevation\"),\n","    gr.Number(label=\"Aspect\"),\n","    gr.Number(label=\"Slope\"),\n","    gr.Number(label=\"Horizontal Distance to Hydrology\"),\n","    gr.Number(label=\"Vertical Distance to Hydrology\"),\n","    gr.Number(label=\"Horizontal Distance to Roadways\"),\n","    gr.Number(label=\"Hillshade 9am\"),\n","    gr.Number(label=\"Hillshade Noon\"),\n","    gr.Number(label=\"Hillshade 3pm\"),\n","    gr.Number(label=\"Horizontal Distance to Fire Points\"),\n","    gr.Checkbox(label=\"Wilderness Area 1\"),\n","    gr.Checkbox(label=\"Wilderness Area 2\"),\n","    gr.Checkbox(label=\"Wilderness Area 3\"),\n","    gr.Checkbox(label=\"Wilderness Area 4\")\n","] + [gr.Checkbox(label=f\"Soil Type {i}\") for i in range(1, 41)]\n","\n","output = gr.Label(label=\"Cover Type\")\n","\n","app = gr.Interface(fn=predict_forest_cover, inputs=inputs, outputs=output, live=True)\n","\n","# Launch the app\n","app.launch()\n","test_data = [\n","    (0, 2550, 48, 11, 110, 22, 210, 155, 210, 215, 520, 0, 1, 0, 0, *[0]*40),\n","]\n"]},{"cell_type":"code","execution_count":null,"id":"f1450ece-5bf0-4158-ae87-4bbda6fe6852","metadata":{"id":"f1450ece-5bf0-4158-ae87-4bbda6fe6852","outputId":"75b64abd-1f93-4286-e948-f12e49edefe8"},"outputs":[{"name":"stdout","output_type":"stream","text":["* Running on local URL:  http://127.0.0.1:7865\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"data":{"text/html":["<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":23,"metadata":{},"output_type":"execute_result"},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n","    response = await route_utils.call_process_api(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n","    output = await app.get_blocks().process_api(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2047, in process_api\n","    result = await self.call_function(\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1594, in call_function\n","    prediction = await anyio.to_thread.run_sync(  # type: ignore\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n","    return await get_async_backend().run_sync_in_worker_thread(\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n","    return await future\n","           ^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n","    result = context.run(func, *args)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py\", line 869, in wrapper\n","    response = f(*args, **kwargs)\n","               ^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_13100\\2218240117.py\", line 38, in predict_forest_cover\n","    input_df = spark.createDataFrame(data, schema=columns)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py\", line 1443, in createDataFrame\n","    return self._create_dataframe(\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py\", line 1485, in _create_dataframe\n","    rdd, struct = self._createFromLocal(map(prepare, data), schema)\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py\", line 1098, in _createFromLocal\n","    struct.fields[i].name = name\n","    ~~~~~~~~~~~~~^^^\n","IndexError: list index out of range\n"]},{"name":"stdout","output_type":"stream","text":["Created dataset file at: .gradio\\flagged\\dataset2.csv\n"]}],"source":["import gradio as gr\n","from pyspark.ml.classification import RandomForestClassificationModel\n","from pyspark.sql import SparkSession\n","from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql import functions as F\n","\n","# Initialize Spark session\n","spark = SparkSession.builder \\\n","    .appName(\"RandomForestDeployment\") \\\n","    .getOrCreate()\n","\n","# Load the trained Random Forest model\n","#model_path =\n","model = rf_model\n","\n","from pyspark.ml.feature import VectorAssembler, StandardScaler\n","from pyspark.sql import DataFrame\n","\n","def predict_forest_cover(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","                         Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","                         Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","                         Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","                         Wilderness_Area3, Wilderness_Area4, *Soil_Types):\n","    # Create a DataFrame for the input\n","    data = [(Id, Elevation, Aspect, Slope, Horizontal_Distance_To_Hydrology,\n","             Vertical_Distance_To_Hydrology, Horizontal_Distance_To_Roadways,\n","             Hillshade_9am, Hillshade_Noon, Hillshade_3pm,\n","             Horizontal_Distance_To_Fire_Points, Wilderness_Area1, Wilderness_Area2,\n","             Wilderness_Area3, Wilderness_Area4, *Soil_Types)]\n","    columns = [\n","        \"Id\", \"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\",\n","        \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\",\n","        \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",\n","        \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\",\n","        \"Wilderness_Area3\", \"Wilderness_Area4\"\n","    ] + [f\"Soil_Type{i}\" for i in range(1, 41)]\n","\n","    input_df = spark.createDataFrame(data, schema=columns)\n","\n","    # Assemble features into a single vector column\n","    feature_cols = columns[1:]  # Exclude \"Id\"\n","    assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n","    assembled_df = assembler.transform(input_df)\n","\n","    # Scale the features\n","    scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\", withMean=True, withStd=True)\n","    scaler_model = scaler.fit(assembled_df)\n","    scaled_df = scaler_model.transform(assembled_df)\n","\n","    # Predict using the trained model\n","    predictions = model.transform(scaled_df)\n","    prediction = predictions.select(\"prediction\").collect()[0][\"prediction\"]\n","\n","    return int(prediction)\n","\n","\n","# Define Gradio interface\n","inputs = [\n","    gr.Number(label=\"Elevation\"),\n","    gr.Number(label=\"Aspect\"),\n","    gr.Number(label=\"Slope\"),\n","    gr.Number(label=\"Horizontal Distance to Hydrology\"),\n","    gr.Number(label=\"Vertical Distance to Hydrology\"),\n","    gr.Number(label=\"Horizontal Distance to Roadways\"),\n","    gr.Number(label=\"Hillshade 9am\"),\n","    gr.Number(label=\"Hillshade Noon\"),\n","    gr.Number(label=\"Hillshade 3pm\"),\n","    gr.Number(label=\"Horizontal Distance to Fire Points\"),\n","    gr.Checkbox(label=\"Wilderness Area 1\"),\n","    gr.Checkbox(label=\"Wilderness Area 2\"),\n","    gr.Checkbox(label=\"Wilderness Area 3\"),\n","    gr.Checkbox(label=\"Wilderness Area 4\")\n","] + [gr.Checkbox(label=f\"Soil Type {i}\") for i in range(1, 41)]\n","\n","\n","output = gr.Label(label=\"Cover Type\")\n","\n","app = gr.Interface(fn=predict_forest_cover, inputs=inputs, outputs=output)\n","\n","# Launch the app\n","app.launch()\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}